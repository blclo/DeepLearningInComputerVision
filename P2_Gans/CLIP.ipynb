{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmhIbuMf5n7I",
        "outputId": "b135dedf-88a8-4116-b65d-fc1ef0a4a0f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'StyleCLIP'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 30 (delta 12), reused 10 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (30/30), 13.88 KiB | 1.26 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vipermu/StyleCLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF5gxh2K5yWM",
        "outputId": "3559dbed-58a1-4c99-bf1d-655c961a2b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/StyleCLIP\n"
          ]
        }
      ],
      "source": [
        "%cd StyleCLIP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9lS-psCrTAW",
        "outputId": "0020ac12-9edf-4900-9854-63a7d84531bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-ytxgwsp4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-ytxgwsp4\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.15.2+cu118)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369370 sha256=9ab34ad70ab7de9eb9414bd33e43efd57214f654eb659c89c7ec7b6ac9c8b051\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zu8_nofy/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy==5.8 opencv-python==4.5.1.48 regex==2020.11.13 torch==1.7.1 tqdm==4.56.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq39PLP2rX6V",
        "outputId": "43f045fe-f8c8-4532-bba4-30bc06587927"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ftfy==5.8\n",
            "  Downloading ftfy-5.8.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencv-python==4.5.1.48\n",
            "  Downloading opencv-python-4.5.1.48.tar.gz (88.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QniM51wu65PD",
        "outputId": "e54d884e-9921-4917-c70a-863151029913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING  cpu\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "torch.Size([1, 1, 512])\n",
            "torch.Size([1, 1, 512])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleCLIP/clip_generate.py\", line 170, in <module>\n",
            "    img = g_synthesis(dlatents)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/StyleCLIP/stylegan_models.py\", line 369, in forward\n",
            "    x = m(x, dlatents_in[:, 2*i:2*i+2])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/StyleCLIP/stylegan_models.py\", line 305, in forward\n",
            "    x = self.conv0_up(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/StyleCLIP/stylegan_models.py\", line 75, in forward\n",
            "    x = F.conv_transpose2d(x, w, stride=2, padding=(w.size(-1)-1)//2)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python clip_generate.py --prompt \"The image of a woman with blonde hair and purple eyes\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv7eISoaUjFZ",
        "outputId": "657b856e-ac34-444f-e06d-030eca1e7900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING  cpu\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4079: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Step 0\n",
            "Loss 4.467414855957031\n",
            "Step 5\n",
            "Loss 4.126681327819824\n",
            "Step 10\n",
            "Loss 3.9216055870056152\n",
            "Step 15\n",
            "Loss 3.693366050720215\n",
            "Step 20\n",
            "Loss 3.6272671222686768\n",
            "Step 25\n",
            "Loss 3.587885856628418\n",
            "Step 30\n",
            "Loss 3.7481002807617188\n",
            "Step 35\n",
            "Loss 3.436781883239746\n",
            "Step 40\n",
            "Loss 3.378074884414673\n",
            "Step 45\n",
            "Loss 3.005136251449585\n",
            "Step 50\n",
            "Loss 3.0298843383789062\n",
            "Step 55\n",
            "Loss 2.9726128578186035\n",
            "Step 60\n",
            "Loss 3.125199794769287\n",
            "Step 65\n",
            "Loss 3.041764259338379\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleCLIP/clip_generate.py\", line 169, in <module>\n",
            "    img = g_synthesis(dlatents)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/StyleCLIP/stylegan_models.py\", line 369, in forward\n",
            "    x = m(x, dlatents_in[:, 2*i:2*i+2])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/StyleCLIP/stylegan_models.py\", line 307, in forward\n",
            "    x = self.conv1(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/StyleCLIP/stylegan_models.py\", line 81, in forward\n",
            "    return F.conv2d(x, self.weight * self.w_mul, bias, padding=self.kernel_size//2)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python clip_generate.py --prompt \"The image of a blond kid with green eyes\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxRX1VoiihX8",
        "outputId": "9e87c3b4-2288-4020-ca25-0bdc307e4db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USING  cpu\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4079: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Step 0\n",
            "Loss 5.320103645324707\n",
            "Step 5\n",
            "Loss 4.758937835693359\n",
            "Step 10\n",
            "Loss 4.335372447967529\n",
            "Step 15\n",
            "Loss 4.18013858795166\n",
            "Step 20\n",
            "Loss 4.257621765136719\n",
            "Step 25\n",
            "Loss 3.95989990234375\n",
            "Step 30\n",
            "Loss 3.8213534355163574\n",
            "Step 35\n",
            "Loss 4.04053258895874\n",
            "Step 40\n",
            "Loss 3.755114793777466\n",
            "Step 45\n",
            "Loss 3.6629836559295654\n",
            "Step 50\n",
            "Loss 3.583993911743164\n",
            "Step 55\n",
            "Loss 3.564685344696045\n",
            "Step 60\n",
            "Loss 3.5122666358947754\n",
            "Step 65\n",
            "Loss 3.484363555908203\n",
            "Step 70\n",
            "Loss 3.3610730171203613\n",
            "Step 75\n",
            "Loss 3.342193126678467\n",
            "Step 80\n",
            "Loss 3.2615861892700195\n",
            "Step 85\n",
            "Loss 3.2456564903259277\n",
            "Step 90\n",
            "Loss 3.220223903656006\n",
            "Step 95\n",
            "Loss 3.186666250228882\n",
            "Step 100\n",
            "Loss 3.1502585411071777\n",
            "Step 105\n",
            "Loss 3.1233091354370117\n",
            "Step 110\n",
            "Loss 3.138319969177246\n",
            "Step 115\n",
            "Loss 3.159134864807129\n",
            "Step 120\n",
            "Loss 3.1027426719665527\n",
            "Step 125\n",
            "Loss 3.0694754123687744\n",
            "Step 130\n",
            "Loss 3.0985538959503174\n",
            "Step 135\n",
            "Loss 3.0817086696624756\n",
            "Step 140\n",
            "Loss 3.0964548587799072\n",
            "Step 145\n",
            "Loss 3.091421127319336\n",
            "Step 150\n",
            "Loss 3.0952224731445312\n",
            "Step 155\n",
            "Loss 3.097116470336914\n",
            "Step 160\n",
            "Loss 3.0997891426086426\n",
            "Step 165\n",
            "Loss 3.0953049659729004\n",
            "Step 170\n",
            "Loss 3.0506415367126465\n",
            "Step 175\n",
            "Loss 3.03810977935791\n",
            "Step 180\n",
            "Loss 3.12376070022583\n",
            "Step 185\n",
            "Loss 3.0414228439331055\n",
            "Step 190\n",
            "Loss 2.999683141708374\n",
            "Step 195\n",
            "Loss 3.02870512008667\n",
            "Step 200\n",
            "Loss 2.9977617263793945\n",
            "Step 205\n",
            "Loss 2.9563968181610107\n",
            "Step 210\n",
            "Loss 3.00734543800354\n",
            "Step 215\n",
            "Loss 2.998328924179077\n",
            "Step 220\n",
            "Loss 2.963196039199829\n",
            "Step 225\n",
            "Loss 2.9425814151763916\n",
            "Step 230\n",
            "Loss 2.941431999206543\n",
            "Step 235\n",
            "Loss 2.9565343856811523\n",
            "Step 240\n",
            "Loss 3.012037754058838\n",
            "Step 245\n",
            "Loss 2.9860763549804688\n",
            "Step 250\n",
            "Loss 2.9744203090667725\n",
            "Step 255\n",
            "Loss 2.953788995742798\n",
            "Step 260\n",
            "Loss 2.9845995903015137\n",
            "Step 265\n",
            "Loss 2.987506628036499\n",
            "Step 270\n",
            "Loss 2.9750168323516846\n",
            "Step 275\n",
            "Loss 2.9332075119018555\n",
            "Step 280\n",
            "Loss 2.9715709686279297\n",
            "Step 285\n",
            "Loss 2.926616668701172\n",
            "Step 290\n",
            "Loss 2.929281711578369\n",
            "Step 295\n",
            "Loss 2.916900873184204\n",
            "Step 300\n",
            "Loss 2.9402108192443848\n",
            "Step 305\n",
            "Loss 2.935013771057129\n",
            "Step 310\n",
            "Loss 2.9114716053009033\n",
            "Step 315\n",
            "Loss 2.875206708908081\n",
            "Step 320\n",
            "Loss 2.8882904052734375\n",
            "Step 325\n",
            "Loss 2.894045829772949\n",
            "Step 330\n",
            "Loss 2.8934333324432373\n",
            "Step 335\n",
            "Loss 2.9001240730285645\n",
            "Step 340\n",
            "Loss 2.9320740699768066\n",
            "Step 345\n",
            "Loss 2.861513376235962\n",
            "Step 350\n",
            "Loss 2.9113621711730957\n",
            "Step 355\n",
            "Loss 2.905634641647339\n",
            "Step 360\n",
            "Loss 2.852745532989502\n",
            "Step 365\n",
            "Loss 2.857572555541992\n",
            "Step 370\n",
            "Loss 2.886869192123413\n",
            "Step 375\n",
            "Loss 2.862546920776367\n",
            "Step 380\n",
            "Loss 2.8560397624969482\n",
            "Step 385\n",
            "Loss 2.8583099842071533\n",
            "Step 390\n",
            "Loss 2.857071876525879\n",
            "Step 395\n",
            "Loss 2.8292884826660156\n",
            "Step 400\n",
            "Loss 2.846503734588623\n",
            "Step 405\n",
            "Loss 2.8601624965667725\n",
            "Step 410\n",
            "Loss 2.8405404090881348\n",
            "Step 415\n",
            "Loss 2.831005573272705\n",
            "Step 420\n",
            "Loss 2.8261537551879883\n",
            "Step 425\n",
            "Loss 2.8449888229370117\n",
            "Step 430\n",
            "Loss 2.8264055252075195\n",
            "Step 435\n",
            "Loss 2.8411412239074707\n",
            "Step 440\n",
            "Loss 2.812802791595459\n",
            "Step 445\n",
            "Loss 2.8295505046844482\n",
            "Step 450\n",
            "Loss 2.8272781372070312\n",
            "Step 455\n",
            "Loss 2.828768491744995\n",
            "Step 460\n",
            "Loss 2.7937517166137695\n",
            "Step 465\n",
            "Loss 2.8050239086151123\n",
            "Step 470\n",
            "Loss 2.789608955383301\n",
            "Step 475\n",
            "Loss 2.785423755645752\n",
            "Step 480\n",
            "Loss 2.820615768432617\n",
            "Step 485\n",
            "Loss 2.803168296813965\n",
            "Step 490\n",
            "Loss 2.807281970977783\n",
            "Step 495\n",
            "Loss 2.7928404808044434\n",
            "Step 500\n",
            "Loss 2.784553050994873\n",
            "Step 505\n",
            "Loss 2.8169615268707275\n",
            "Step 510\n",
            "Loss 2.7793030738830566\n",
            "Step 515\n",
            "Loss 2.7948358058929443\n",
            "Step 520\n",
            "Loss 2.7810311317443848\n",
            "Step 525\n",
            "Loss 2.782463550567627\n",
            "Step 530\n",
            "Loss 2.7789578437805176\n",
            "Step 535\n",
            "Loss 2.79464054107666\n",
            "Step 540\n",
            "Loss 2.7780144214630127\n",
            "Step 545\n",
            "Loss 2.7706570625305176\n",
            "Step 550\n",
            "Loss 2.7987771034240723\n",
            "Step 555\n",
            "Loss 2.773949146270752\n",
            "Step 560\n",
            "Loss 2.7708754539489746\n",
            "Step 565\n",
            "Loss 2.7680864334106445\n",
            "Step 570\n",
            "Loss 2.7759954929351807\n",
            "Step 575\n",
            "Loss 2.7605526447296143\n",
            "Step 580\n",
            "Loss 2.754523754119873\n",
            "Step 585\n",
            "Loss 2.7623071670532227\n",
            "Step 590\n",
            "Loss 2.743889808654785\n",
            "Step 595\n",
            "Loss 2.775336265563965\n",
            "Step 600\n",
            "Loss 2.9921278953552246\n",
            "Step 605\n",
            "Loss 3.047645092010498\n",
            "Step 610\n",
            "Loss 2.930706024169922\n",
            "Step 615\n",
            "Loss 2.861845016479492\n",
            "Step 620\n",
            "Loss 2.851696014404297\n",
            "Step 625\n",
            "Loss 2.90248441696167\n",
            "Step 630\n",
            "Loss 2.860684633255005\n",
            "Step 635\n",
            "Loss 2.8438563346862793\n",
            "Step 640\n",
            "Loss 2.833287000656128\n",
            "Step 645\n",
            "Loss 2.826608180999756\n",
            "Step 650\n",
            "Loss 2.845276355743408\n",
            "Step 655\n",
            "Loss 2.802457809448242\n",
            "Step 660\n",
            "Loss 2.8141705989837646\n",
            "Step 665\n",
            "Loss 2.7852649688720703\n",
            "Step 670\n",
            "Loss 2.8227620124816895\n",
            "Step 675\n",
            "Loss 2.813131809234619\n",
            "Step 680\n",
            "Loss 2.818816661834717\n",
            "Step 685\n",
            "Loss 2.7789039611816406\n",
            "Step 690\n",
            "Loss 2.7802157402038574\n",
            "Step 695\n",
            "Loss 2.782024621963501\n",
            "Step 700\n",
            "Loss 2.7973384857177734\n",
            "Step 705\n",
            "Loss 2.7941808700561523\n",
            "Step 710\n",
            "Loss 2.750230312347412\n",
            "Step 715\n",
            "Loss 2.7920784950256348\n",
            "Step 720\n",
            "Loss 2.767134666442871\n",
            "Step 725\n",
            "Loss 2.759174346923828\n",
            "Step 730\n",
            "Loss 2.7635178565979004\n",
            "Step 735\n",
            "Loss 2.758880615234375\n",
            "Step 740\n",
            "Loss 2.735100030899048\n",
            "Step 745\n",
            "Loss 2.7512314319610596\n",
            "Step 750\n",
            "Loss 2.7496962547302246\n",
            "Step 755\n",
            "Loss 2.7661256790161133\n",
            "Step 760\n",
            "Loss 2.7543234825134277\n",
            "Step 765\n",
            "Loss 2.773265838623047\n",
            "Step 770\n",
            "Loss 2.752702474594116\n",
            "Step 775\n",
            "Loss 2.7253293991088867\n",
            "Step 780\n",
            "Loss 2.7621536254882812\n"
          ]
        }
      ],
      "source": [
        "!python clip_generate.py --prompt \"The image of a blond kid with green eyes\" --ref_img_path \"/content/StyleCLIP/references/align-black_kid.png\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}