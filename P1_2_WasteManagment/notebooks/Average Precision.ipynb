{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224589c1",
   "metadata": {},
   "source": [
    "# Get GTs crops with 'can' label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cff9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "file_path = \"/work3/s212725/WasteProject/data/json/corrected_test_region_proposals_3.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path) as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a30958d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "gts_with_path = []\n",
    "# Access and work with the loaded data\n",
    "for path, label in data.items():\n",
    "    if 'gt' in path:\n",
    "        if label == 6:\n",
    "            gts_with_path.append(path)\n",
    "\n",
    "print(len(gts_with_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96876661",
   "metadata": {},
   "source": [
    "Let's save the gts paths in a file so that we can use them later to run the IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e42f08d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the path to your pickle file\n",
    "file_path = \"/work3/s212725/WasteProject/data/json/cans_gt_paths.pickle\"\n",
    "\n",
    "# Save the array to a pickle file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(gts_with_path, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed94ea",
   "metadata": {},
   "source": [
    "THERE ARE 38 GTs WITH CAN LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcf9b6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23224\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "file_path = \"/work3/s212725/WasteProject/data/json/corrected_test_region_proposals_3.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path) as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acfde3a",
   "metadata": {},
   "source": [
    "# Remove the gt crops from the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc075d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "file_path = \"/work3/s212725/WasteProject/data/json/corrected_test_region_proposals_3.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path) as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Iterate over the data and remove entries containing 'gt'\n",
    "updated_data = {path: label for path, label in data.items() if 'gt' not in path}\n",
    "\n",
    "new_file_path = \"/work3/s212725/WasteProject/data/json/new_corrected_test_region_proposals_3.json\"\n",
    "# Write the updated data back to the JSON file\n",
    "with open(new_file_path, 'w') as file:\n",
    "    json.dump(updated_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5eea5",
   "metadata": {},
   "source": [
    "# Let's do the testing and get the outputs per crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51fc0969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - using device: cuda:0\n",
      "\n",
      "INFO - LOADED EXPERIMENT: ResNet18-lr1e-05.wd0.001.bz32.seed14\n",
      "INFO -  model: {'name': 'ResNet18'}\n",
      "INFO -  seed: 14\n",
      "INFO -  best epoch: 1\n",
      "INFO -  data: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:22<00:00, 84.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1205\n",
      "Test accuracy: 97.48%\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# \n",
    "\n",
    "import os\n",
    "from pathlib2 import Path\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import wandb\n",
    "import pickle\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data.rp_dataloader import RegionProposalsDatasetTrain, RegionProposalsDataset\n",
    "from src.data.data_sampler import BalancedSampler\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import trange, tqdm\n",
    "from src.models.model import get_model\n",
    "from src.models.utils import set_seed, load_experiment\n",
    "import json\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 12\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(seed=14)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"INFO - using device: {device}\")\n",
    "\n",
    "# ---------------------------- Load Model Checkpoint ---------------------------- #\n",
    "experiment_checkpoint   = 'ResNet18-lr1e-05.wd0.001.bz32.seed14/best.ckpt'\n",
    "# Define experiment path\n",
    "BASE_PATH = Path(r\"/work3/s212725/WasteProject\")\n",
    "experiment_path = BASE_PATH / 'models' / experiment_checkpoint\n",
    "\n",
    "# Load experiment stored from training\n",
    "model_name, model, criterion = load_experiment(experiment_path, device=device)\n",
    "model.eval()\n",
    "\n",
    "#  ---------------  Datasets  ---------------\n",
    "# define transforms to resize - warping proposals\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "paths_to_probs = {}\n",
    "path_test = r\"/work3/s212725/WasteProject/data/json/new_corrected_test_region_proposals_3.json\"\n",
    "test_dataset = RegionProposalsDataset(path_test, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# ---------------- Testing loop ---------------- #\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    for batch in tqdm(test_loader):\n",
    "        images, labels, paths = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward + backward\n",
    "        outputs = model(images)\n",
    "        probs = torch.exp(outputs)\n",
    "        preds = torch.exp(outputs).topk(1)[1]\n",
    "        \n",
    "        for path, prob in zip(paths, probs):\n",
    "            paths_to_probs[path] = prob.tolist()\n",
    "\n",
    "        # Compute loss\n",
    "        batch_loss = criterion(outputs, labels)\n",
    "        test_loss += batch_loss.item()\n",
    "\n",
    "        # Compute accuracy\n",
    "        batch_correct = (preds.squeeze() == labels).sum().item()\n",
    "        test_correct += batch_correct\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "    # Compute average loss and accuracy\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    avg_test_acc = test_correct / test_total\n",
    "\n",
    "    print('Test loss: {:.4f}'.format(avg_test_loss))\n",
    "    print('Test accuracy: {:.2%}'.format(avg_test_acc))\n",
    "    \n",
    "# Specify the path for the new JSON file\n",
    "output_file_path = \"/work3/s212725/WasteProject/data/json/paths_to_probs.json\"\n",
    "\n",
    "# Write the dictionary to a JSON file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    json.dump(paths_to_probs, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c4a90",
   "metadata": {},
   "source": [
    "Let's analyse the output of probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c5a23a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "[0.0002820167865138501, 0.00012348090240266174, 0.00022869101667311043, 0.00026242044987156987, 0.0003906650235876441, 0.00030790004529990256, 0.00027280644280835986, 0.0003325119032524526, 0.0002215070417150855, 0.00023304748174268752, 0.0002988692722283304, 0.00025941463536582887, 0.0004322165041230619, 0.00032813448342494667, 0.00033234074362553656, 0.00039599090814590454, 0.0004831827827729285, 0.0002354155294597149, 0.00030198448803275824, 0.0001878525799838826, 0.0003268330474384129, 0.00024096171546261758, 0.00011404857650632039, 0.0005037937080487609, 0.0005702293128706515, 0.00023292815603781492, 0.0002569080679677427, 0.0005454313359223306, 0.991298258304596]\n",
      "0.00027280644280835986\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "file_path = \"/work3/s212725/WasteProject/data/json/paths_to_probs.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path) as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "for path, prob in data.items():\n",
    "    print(prob[6])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28f9c1",
   "metadata": {},
   "source": [
    "Let's order the paths based in the order of probs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea33b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to the JSON file\n",
    "input_file_path = \"/work3/s212725/WasteProject/data/json/paths_to_probs.json\"\n",
    "output_file_path = \"/work3/s212725/WasteProject/data/json/paths_to_probs_ordered.json\"\n",
    "\n",
    "# Load the data from the JSON file\n",
    "with open(input_file_path) as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Sort the data based on prob[6] in decreasing order\n",
    "sorted_data = sorted(data.items(), key=lambda x: x[1][6], reverse=True)\n",
    "\n",
    "# Create a new ordered dictionary\n",
    "ordered_data = {}\n",
    "for path, prob in sorted_data:\n",
    "    ordered_data[path] = prob\n",
    "\n",
    "# Write the ordered data to a new JSON file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    json.dump(ordered_data, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a150d4",
   "metadata": {},
   "source": [
    "Are there actually any can gts in the new crops?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af1105e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "file_path = \"/work3/s212725/WasteProject/data/json/new_corrected_test_region_proposals_3.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path) as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "cans_in_crops = []\n",
    "# Access and work with the loaded data\n",
    "for path, label in data.items():\n",
    "    if label == 6:\n",
    "        cans_in_crops.append(path)\n",
    "\n",
    "print(len(cans_in_crops))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d7f7e7",
   "metadata": {},
   "source": [
    "Yes there are 44"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
